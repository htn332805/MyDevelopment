# Exercise 5A: Core Infrastructure Foundation

**Duration:** 90-120 minutes  
**Difficulty:** Advanced-Foundation  
**Prerequisites:** Completed Exercises 1-4  
**Focus:** Building reusable infrastructure components for all future Framework0 recipes

## ðŸŽ¯ Learning Objectives

By the end of this exercise, you will have created:

- **Comprehensive Logging Framework** - Structured logging with multiple outputs and log levels
- **System Health Monitoring** - Real-time health checks and system metrics collection
- **Performance Metrics System** - Built-in benchmarking and performance tracking
- **Robust Error Handling** - Centralized error management with recovery strategies
- **Configuration Management** - Flexible, environment-aware configuration system
- **Traceability Infrastructure** - Complete execution flow tracking and debugging support

## ðŸ“š Foundation Architecture Concepts

### Core Infrastructure Design Principles

The Framework0 Foundation Infrastructure follows these key principles:

- **Observable by Default**: Every component includes built-in logging, metrics, and tracing
- **Fail-Safe Operations**: Graceful degradation with automatic recovery mechanisms
- **Configuration-Driven**: Behavior controlled through external configuration
- **Dependency-Ready**: Designed to be imported and extended by other recipes
- **Performance-Aware**: Built-in performance monitoring and optimization
- **Debug-Friendly**: Comprehensive diagnostic information at every level

### Infrastructure Component Architecture

```
Framework0 Foundation Infrastructure
â”œâ”€â”€ Logging Framework
â”‚   â”œâ”€â”€ Structured JSON logging
â”‚   â”œâ”€â”€ Multiple output targets (file, console, remote)
â”‚   â”œâ”€â”€ Log level management
â”‚   â””â”€â”€ Context-aware log correlation
â”œâ”€â”€ Health Monitoring
â”‚   â”œâ”€â”€ System resource monitoring
â”‚   â”œâ”€â”€ Application health checks  
â”‚   â”œâ”€â”€ Dependency availability checks
â”‚   â””â”€â”€ Real-time alerting
â”œâ”€â”€ Performance Metrics
â”‚   â”œâ”€â”€ Execution time tracking
â”‚   â”œâ”€â”€ Resource utilization monitoring
â”‚   â”œâ”€â”€ Throughput measurement
â”‚   â””â”€â”€ Performance regression detection
â”œâ”€â”€ Error Management
â”‚   â”œâ”€â”€ Centralized error handling
â”‚   â”œâ”€â”€ Error categorization and routing
â”‚   â”œâ”€â”€ Automatic recovery strategies
â”‚   â””â”€â”€ Error notification and escalation
â””â”€â”€ Configuration System
    â”œâ”€â”€ Environment-aware settings
    â”œâ”€â”€ Runtime configuration updates
    â”œâ”€â”€ Configuration validation
    â””â”€â”€ Secure credential management
```

### Reusability and Dependency Patterns

**Foundation recipes are designed to be inherited:**

```yaml
# Any future recipe can import foundation capabilities
steps:
  - name: "initialize_infrastructure" 
    type: "sub_recipe"
    recipe_path: "foundation/infrastructure_bootstrap.yaml"
    parameters:
      logging_level: "info"
      monitoring_enabled: true
      performance_tracking: true
      
  - name: "your_business_logic"
    depends_on: ["initialize_infrastructure"]
    # Now has access to logging, monitoring, metrics, error handling
```

## ðŸ› ï¸ Exercise Steps

### Step 1: Create Foundation Directory Structure

Let's establish the foundation infrastructure organization:

**ðŸ“ Create foundation structure:**

```bash
mkdir -p FYI/exercises/foundation/{recipes,scriptlets,config,schemas,templates}
mkdir -p FYI/exercises/foundation/recipes/{logging,monitoring,metrics,error_handling,config_management}
mkdir -p FYI/exercises/foundation/config/{environments,schemas,templates}
mkdir -p FYI/exercises/foundation/logs/{application,system,audit,performance}
mkdir -p FYI/exercises/foundation/metrics/{execution,performance,health,business}
```

**ðŸ“ Create:** `FYI/exercises/foundation/config/foundation_config.json`

```json
{
  "foundation": {
    "version": "1.0.0",
    "infrastructure_mode": "comprehensive",
    "debug_level": "info",
    "environment": "development"
  },
  "logging": {
    "framework": {
      "enabled": true,
      "level": "info",
      "format": "structured_json",
      "outputs": ["console", "file"],
      "file_path": "FYI/exercises/foundation/logs/application/framework0.log",
      "rotation": {
        "enabled": true,
        "max_size_mb": 100,
        "max_files": 10
      }
    },
    "audit": {
      "enabled": true,
      "file_path": "FYI/exercises/foundation/logs/audit/audit.log",
      "include_context": true,
      "include_parameters": true
    },
    "performance": {
      "enabled": true,
      "file_path": "FYI/exercises/foundation/logs/performance/metrics.log",
      "detailed_timing": true,
      "resource_monitoring": true
    }
  },
  "monitoring": {
    "health_checks": {
      "enabled": true,
      "interval_seconds": 30,
      "checks": ["system_resources", "disk_space", "memory_usage", "dependency_availability"]
    },
    "system_metrics": {
      "enabled": true,
      "collection_interval_seconds": 10,
      "metrics": ["cpu_usage", "memory_usage", "disk_io", "network_io"]
    },
    "application_metrics": {
      "enabled": true,
      "track_execution_time": true,
      "track_error_rates": true,
      "track_throughput": true
    }
  },
  "performance": {
    "benchmarking": {
      "enabled": true,
      "baseline_collection": true,
      "regression_detection": true,
      "performance_targets": {
        "max_execution_time_seconds": 60,
        "max_memory_usage_mb": 1024,
        "min_throughput_ops_per_second": 10
      }
    }
  },
  "error_handling": {
    "centralized_handling": true,
    "error_categorization": true,
    "automatic_recovery": {
      "enabled": true,
      "max_retry_attempts": 3,
      "backoff_strategy": "exponential"
    },
    "notifications": {
      "enabled": true,
      "channels": ["log", "console"],
      "escalation_rules": {
        "critical_errors": "immediate",
        "warning_errors": "batched",
        "info_errors": "log_only"
      }
    }
  },
  "configuration": {
    "management": {
      "validation_enabled": true,
      "environment_override": true,
      "runtime_updates": false,
      "secure_credentials": true
    }
  }
}
```

### Step 2: Create Core Infrastructure Bootstrap Recipe

This is the master recipe that initializes all foundation infrastructure:

**ðŸ“ Create:** `FYI/exercises/foundation/recipes/infrastructure_bootstrap.yaml`

```yaml
metadata:
  name: "framework0_infrastructure_bootstrap"
  version: "1.0.0"
  description: "Core infrastructure initialization for all Framework0 recipes"
  author: "Framework0 Foundation Team"
  tags: ["foundation", "infrastructure", "logging", "monitoring", "required"]
  category: "core_infrastructure"
  
  # This recipe is designed to be imported by all other recipes
  usage_pattern: "dependency"
  compatibility: ["all_recipes"]
  
parameters:
  - name: "logging_level"
    description: "Global logging level (debug, info, warn, error, critical)"
    required: false
    default: "info"
  - name: "monitoring_enabled"
    description: "Enable system monitoring and health checks"
    required: false
    default: true
  - name: "performance_tracking"
    description: "Enable performance metrics collection"
    required: false
    default: true
  - name: "error_recovery_enabled"
    description: "Enable automatic error recovery mechanisms"
    required: false
    default: true

steps:
  # === CONFIGURATION INITIALIZATION ===
  - name: "initialize_foundation_config"
    idx: 1
    type: "python"
    module: "scriptlets.foundation"
    function: "FoundationConfigInitializerScriptlet"
    description: "Load and validate foundation configuration"
    args:
      config_path: "FYI/exercises/foundation/config/foundation_config.json"
      environment_override: true
      parameter_injection:
        logging_level: "#{params.logging_level}"
        monitoring_enabled: "#{params.monitoring_enabled}"
        performance_tracking: "#{params.performance_tracking}"
        error_recovery_enabled: "#{params.error_recovery_enabled}"

  # === LOGGING FRAMEWORK INITIALIZATION ===
  - name: "initialize_logging_framework"
    idx: 2
    type: "python"
    module: "scriptlets.foundation"
    function: "LoggingFrameworkScriptlet"
    depends_on: ["initialize_foundation_config"]
    description: "Initialize comprehensive logging infrastructure"
    args:
      logging_config: "#{context.get('foundation.config.logging')}"
      create_log_directories: true
      setup_log_rotation: true
      configure_structured_logging: true

  # === HEALTH MONITORING INITIALIZATION ===
  - name: "initialize_health_monitoring"
    idx: 3
    type: "python"
    module: "scriptlets.foundation"
    function: "HealthMonitoringScriptlet"
    depends_on: ["initialize_logging_framework"]
    condition: "#{params.monitoring_enabled}"
    description: "Initialize system health monitoring and checks"
    args:
      monitoring_config: "#{context.get('foundation.config.monitoring')}"
      start_background_monitoring: true
      setup_health_endpoints: true

  # === PERFORMANCE METRICS INITIALIZATION ===
  - name: "initialize_performance_metrics"
    idx: 4
    type: "python"
    module: "scriptlets.foundation"
    function: "PerformanceMetricsScriptlet"
    depends_on: ["initialize_logging_framework"]
    condition: "#{params.performance_tracking}"
    description: "Initialize performance tracking and metrics collection"
    args:
      metrics_config: "#{context.get('foundation.config.performance')}"
      setup_baseline_collection: true
      enable_real_time_monitoring: true

  # === ERROR HANDLING FRAMEWORK ===
  - name: "initialize_error_handling"
    idx: 5
    type: "python"
    module: "scriptlets.foundation"
    function: "ErrorHandlingFrameworkScriptlet"
    depends_on: ["initialize_logging_framework"]
    condition: "#{params.error_recovery_enabled}"
    description: "Initialize centralized error handling and recovery"
    args:
      error_config: "#{context.get('foundation.config.error_handling')}"
      setup_recovery_strategies: true
      configure_error_routing: true

  # === FOUNDATION READINESS VALIDATION ===
  - name: "validate_foundation_readiness"
    idx: 6
    type: "python"
    module: "scriptlets.foundation"
    function: "FoundationReadinessScriptlet"
    depends_on: ["initialize_logging_framework", "initialize_health_monitoring", "initialize_performance_metrics", "initialize_error_handling"]
    description: "Validate that all foundation infrastructure is ready"
    args:
      validation_checks: ["logging", "monitoring", "metrics", "error_handling"]
      readiness_timeout_seconds: 30
      fail_on_validation_error: true

  # === FOUNDATION STATUS REPORTING ===
  - name: "report_foundation_status"
    idx: 7
    type: "python"
    module: "scriptlets.foundation"
    function: "FoundationStatusReportScriptlet"
    depends_on: ["validate_foundation_readiness"]
    description: "Generate foundation infrastructure status report"
    args:
      include_performance_baseline: true
      include_health_summary: true
      include_configuration_summary: true
      store_status_in_context: true
```

### Step 3: Implement Modular LoggingFrameworkScriptlet - Production-Ready Foundation

Following team guidelines for **modularity** and **single responsibility**, let's break down the logging framework into focused, maintainable modules.

#### ðŸ”§ **Modular Architecture Overview**

```
scriptlets/foundation/logging/
â”œâ”€â”€ core.py           # Enums, data classes, basic utilities (~300 lines)
â”œâ”€â”€ formatters.py     # ContextAwareFormatter and formatting logic (~400 lines)  
â”œâ”€â”€ adapters.py       # Framework0LoggerAdapter and context utilities (~400 lines)
â””â”€â”€ __init__.py       # Module exports and initialization
```

**Main scriptlet:** `scriptlets/foundation/logging_framework.py` (~500 lines - orchestration only)

#### ðŸ“ **Step 3.1: Create Core Logging Infrastructure**

**Create:** `scriptlets/foundation/logging/core.py`

```python
"""
Framework0 Foundation - Core Logging Infrastructure

Core components for structured logging system including:
- Standard log levels and output format enums
- Structured log entry data classes for consistency
- Basic logging utilities and constants
- Type definitions and validation helpers
"""

from typing import Dict, Any, List, Optional, Union
from enum import Enum
from dataclasses import dataclass
from datetime import datetime, timezone
import os

class LogLevel(Enum):
    """
    Standard logging levels with numeric values for filtering.
    Maps to Python logging module standard levels.
    """
    CRITICAL = 50  # Critical errors requiring immediate attention
    ERROR = 40     # Error conditions that need investigation
    WARNING = 30   # Warning conditions that should be noted
    INFO = 20      # General information messages
    DEBUG = 10     # Detailed debugging information
    NOTSET = 0     # No specific level set (inherit from parent)

class LogFormat(Enum):
    """
    Supported log output formats for different use cases.
    Each format serves specific requirements and audiences.
    """
    STRUCTURED_JSON = "structured_json"  # Machine-readable JSON format
    SIMPLE_TEXT = "simple_text"          # Human-readable simple format
    DETAILED_TEXT = "detailed_text"      # Human-readable detailed format

class LogOutput(Enum):
    """
    Supported log output targets for message delivery.
    Each target serves different deployment and operational needs.
    """
    CONSOLE = "console"                  # Standard output for development
    FILE = "file"                        # File output for persistence
    ROTATING_FILE = "rotating_file"      # Rotating file for disk management
    REMOTE_SYSLOG = "remote_syslog"      # Remote syslog for centralized logging

@dataclass
class LogEntry:
    """
    Structured log entry for consistent formatting across all loggers.
    
    Contains all necessary information for comprehensive log analysis:
    - Basic message information (timestamp, level, message)
    - Framework0 context (recipe, step, execution tracking)
    - System context (process, thread identification)
    - Additional data and error information
    """
    timestamp: str                        # ISO format timestamp with timezone
    level: str                           # Log level name (INFO, ERROR, etc.)
    logger_name: str                     # Name of the logger that created entry
    message: str                         # Primary log message content
    context_id: Optional[str] = None     # Framework0 context identifier
    recipe_name: Optional[str] = None    # Name of executing recipe
    step_name: Optional[str] = None      # Name of executing step
    execution_id: Optional[str] = None   # Unique execution identifier
    thread_id: Optional[str] = None      # Thread identifier for parallel tracking
    process_id: Optional[int] = None     # Process identifier for multi-process
    extra_data: Optional[Dict[str, Any]] = None  # Additional structured data
    stack_trace: Optional[str] = None    # Stack trace for errors

class LoggingConfiguration:
    """
    Configuration container for logging system setup.
    Provides validation and type checking for logging parameters.
    """
    
    def __init__(self, config_dict: Dict[str, Any]) -> None:
        """
        Initialize logging configuration from dictionary.
        
        Args:
            config_dict: Configuration dictionary with logging settings
        """
        self._config = config_dict
        self._validate_configuration()
    
    def _validate_configuration(self) -> None:
        """
        Validate configuration structure and required fields.
        Ensures all necessary configuration is present and valid.
        """
        required_sections = ["framework"]  # Minimum required sections
        
        for section in required_sections:
            if section not in self._config:
                raise ValueError(f"Missing required logging section: {section}")
        
        # Validate framework section structure
        framework_config = self._config.get("framework", {})
        if not framework_config.get("enabled", True):
            return  # Skip validation if framework logging disabled
        
        # Validate log level if specified
        level = framework_config.get("level", "INFO")
        if level.upper() not in [lvl.name for lvl in LogLevel]:
            raise ValueError(f"Invalid log level: {level}")
    
    def get_framework_config(self) -> Dict[str, Any]:
        """Get framework logging configuration."""
        return self._config.get("framework", {})
    
    def get_audit_config(self) -> Dict[str, Any]:
        """Get audit logging configuration."""
        return self._config.get("audit", {})
    
    def get_performance_config(self) -> Dict[str, Any]:
        """Get performance logging configuration."""
        return self._config.get("performance", {})
    
    def is_section_enabled(self, section: str) -> bool:
        """Check if logging section is enabled."""
        section_config = self._config.get(section, {})
        return section_config.get("enabled", False)

def create_timestamp() -> str:
    """
    Create standardized ISO format timestamp with UTC timezone.
    
    Returns:
        ISO format timestamp string with timezone information
    """
    return datetime.now(timezone.utc).isoformat()

def validate_log_level(level: str) -> LogLevel:
    """
    Validate and convert string log level to LogLevel enum.
    
    Args:
        level: String representation of log level
        
    Returns:
        LogLevel enum value
        
    Raises:
        ValueError: If log level is not recognized
    """
    try:
        return LogLevel[level.upper()]
    except KeyError:
        valid_levels = [lvl.name for lvl in LogLevel]
        raise ValueError(f"Invalid log level '{level}'. Valid levels: {valid_levels}")

def get_default_logging_config() -> Dict[str, Any]:
    """
    Get default logging configuration for Framework0.
    
    Returns:
        Default configuration dictionary with standard settings
    """
    return {
        "framework": {
            "enabled": True,
            "level": "INFO",
            "outputs": ["console"],
            "file_path": "logs/framework0.log",
            "rotation": {
                "enabled": False,
                "max_size_mb": 100,
                "max_files": 10
            }
        },
        "audit": {
            "enabled": False,
            "file_path": "logs/audit.log",
            "include_context": True,
            "include_parameters": True
        },
        "performance": {
            "enabled": False,
            "file_path": "logs/performance.log",
            "detailed_timing": True,
            "resource_monitoring": False
        }
    }

def merge_logging_configs(base_config: Dict[str, Any], 
                         override_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge logging configurations with override support.
    
    Args:
        base_config: Base configuration dictionary
        override_config: Override configuration dictionary
        
    Returns:
        Merged configuration dictionary
    """
    merged = base_config.copy()
    
    for section, section_config in override_config.items():
        if section in merged:
            # Merge section-level configurations
            if isinstance(section_config, dict):
                merged[section].update(section_config)
            else:
                merged[section] = section_config
        else:
            merged[section] = section_config
    
    return merged
```

#### ðŸ“ **Step 3.2: Create Logging Formatters Module**

**Create:** `scriptlets/foundation/logging/formatters.py`

```python
"""
Framework0 Foundation - Logging Formatters

Specialized formatters for different output formats and targets:
- ContextAwareFormatter for Framework0 integration
- JSON structured formatter for machine parsing
- Human-readable formatters for development and operations
- Error and exception formatting with stack traces
"""

from typing import Dict, Any, Optional
import logging
import json
import threading
import os
import traceback
from dataclasses import asdict

from .core import LogEntry, LogFormat, create_timestamp

class ContextAwareFormatter(logging.Formatter):
    """
    Custom formatter that includes Framework0 context in log entries.
    
    Automatically extracts and includes contextual information:
    - Recipe and step execution context
    - Thread and process identification for parallel execution
    - Execution tracking for distributed operations
    - Custom extra data for specialized logging needs
    """
    
    def __init__(self, format_type: LogFormat, include_context: bool = True) -> None:
        """
        Initialize the context-aware formatter.
        
        Args:
            format_type: The type of formatting to apply (JSON, text, etc.)
            include_context: Whether to include Framework0 context information
        """
        super().__init__()
        self.format_type: LogFormat = format_type
        self.include_context: bool = include_context
        
    def format(self, record: logging.LogRecord) -> str:
        """
        Format log record with Framework0 context information.
        
        Args:
            record: The log record to format
            
        Returns:
            Formatted log message string
        """
        try:
            # Create structured log entry from record
            log_entry = self._create_log_entry_from_record(record)
            
            # Format according to specified type
            if self.format_type == LogFormat.STRUCTURED_JSON:
                return self._format_as_json(log_entry)
            elif self.format_type == LogFormat.DETAILED_TEXT:
                return self._format_as_detailed_text(log_entry)
            else:
                return self._format_as_simple_text(log_entry)
                
        except Exception as formatting_error:
            # Fallback formatting if custom formatting fails
            return self._create_fallback_format(record, formatting_error)
    
    def _create_log_entry_from_record(self, record: logging.LogRecord) -> LogEntry:
        """
        Create structured LogEntry from logging.LogRecord.
        
        Args:
            record: Standard logging record
            
        Returns:
            Structured LogEntry with Framework0 context
        """
        # Extract Framework0 context information from record extras
        context_id = getattr(record, 'context_id', None)
        recipe_name = getattr(record, 'recipe_name', None) 
        step_name = getattr(record, 'step_name', None)
        execution_id = getattr(record, 'execution_id', None)
        extra_data = getattr(record, 'extra_data', None)
        
        # Create log entry with all available information
        log_entry = LogEntry(
            timestamp=create_timestamp(),
            level=record.levelname,
            logger_name=record.name,
            message=record.getMessage(),
            context_id=str(context_id) if context_id else None,
            recipe_name=recipe_name,
            step_name=step_name,
            execution_id=execution_id,
            thread_id=str(threading.get_ident()),
            process_id=os.getpid(),
            extra_data=extra_data
        )
        
        # Add stack trace for error conditions
        if record.levelno >= logging.ERROR and record.exc_info:
            log_entry.stack_trace = "".join(
                traceback.format_exception(*record.exc_info)
            )
        
        return log_entry
    
    def _format_as_json(self, entry: LogEntry) -> str:
        """
        Format log entry as structured JSON.
        
        Args:
            entry: Structured log entry
            
        Returns:
            JSON formatted string
        """
        # Convert dataclass to dictionary and serialize as JSON
        entry_dict = asdict(entry)
        
        # Remove None values for cleaner JSON
        entry_dict = {k: v for k, v in entry_dict.items() if v is not None}
        
        return json.dumps(entry_dict, default=str, ensure_ascii=False)
    
    def _format_as_simple_text(self, entry: LogEntry) -> str:
        """
        Format log entry as simple readable text.
        
        Args:
            entry: Structured log entry
            
        Returns:
            Simple text formatted string
        """
        return (f"{entry.timestamp} [{entry.level:8}] "
                f"{entry.logger_name}: {entry.message}")
    
    def _format_as_detailed_text(self, entry: LogEntry) -> str:
        """
        Format log entry with detailed context information.
        
        Args:
            entry: Structured log entry
            
        Returns:
            Detailed text formatted string with context
        """
        # Build header with system and execution information
        header_parts = [
            f"{entry.timestamp} [{entry.level:8}] {entry.logger_name}",
            f"PID:{entry.process_id} TID:{entry.thread_id}"
        ]
        
        # Add Framework0 context if available
        if entry.recipe_name:
            header_parts.append(f"Recipe:{entry.recipe_name}")
        if entry.step_name:
            header_parts.append(f"Step:{entry.step_name}")
        if entry.execution_id:
            # Truncate execution ID for readability
            short_exec_id = entry.execution_id[:8] if entry.execution_id else ""
            header_parts.append(f"Exec:{short_exec_id}")
        
        # Combine header components
        header = " | ".join(header_parts)
        
        # Format main message
        message_line = f"  â†’ {entry.message}"
        
        # Combine header and message
        result = f"{header}\n{message_line}"
        
        # Add extra data if present
        if entry.extra_data:
            extra_json = json.dumps(entry.extra_data, default=str, indent=2)
            result += f"\n  Extra: {extra_json}"
        
        # Add stack trace if present
        if entry.stack_trace:
            result += f"\n  Stack: {entry.stack_trace}"
        
        return result
    
    def _create_fallback_format(self, record: logging.LogRecord, 
                              error: Exception) -> str:
        """
        Create fallback format when normal formatting fails.
        
        Args:
            record: Original log record
            error: Formatting error that occurred
            
        Returns:
            Basic formatted string with error information
        """
        timestamp = create_timestamp()
        return (f"[LOGGING ERROR] {timestamp} - {record.getMessage()} "
                f"(Format Error: {error})")

class AuditFormatter(ContextAwareFormatter):
    """
    Specialized formatter for audit logging with compliance focus.
    
    Always uses structured JSON format for compliance and security analysis.
    Includes additional audit-specific fields and ensures all required
    information is captured for regulatory and security requirements.
    """
    
    def __init__(self) -> None:
        """Initialize audit formatter with JSON format."""
        super().__init__(LogFormat.STRUCTURED_JSON, include_context=True)
    
    def _create_log_entry_from_record(self, record: logging.LogRecord) -> LogEntry:
        """
        Create audit log entry with additional compliance fields.
        
        Args:
            record: Standard logging record
            
        Returns:
            LogEntry enhanced for audit purposes
        """
        # Get base log entry
        entry = super()._create_log_entry_from_record(record)
        
        # Add audit-specific extra data
        if not entry.extra_data:
            entry.extra_data = {}
        
        # Add audit metadata
        entry.extra_data.update({
            "audit_category": getattr(record, 'audit_category', 'general'),
            "compliance_level": getattr(record, 'compliance_level', 'standard'),
            "audit_source": record.name
        })
        
        return entry

class PerformanceFormatter(ContextAwareFormatter):
    """
    Specialized formatter for performance and metrics logging.
    
    Optimized for performance data analysis and monitoring systems.
    Includes timing information and resource utilization data.
    """
    
    def __init__(self) -> None:
        """Initialize performance formatter with JSON format."""
        super().__init__(LogFormat.STRUCTURED_JSON, include_context=True)
    
    def _create_log_entry_from_record(self, record: logging.LogRecord) -> LogEntry:
        """
        Create performance log entry with metrics data.
        
        Args:
            record: Standard logging record
            
        Returns:
            LogEntry enhanced for performance analysis
        """
        # Get base log entry
        entry = super()._create_log_entry_from_record(record)
        
        # Add performance-specific extra data
        if not entry.extra_data:
            entry.extra_data = {}
        
        # Add performance metadata
        entry.extra_data.update({
            "performance_category": getattr(record, 'performance_category', 'timing'),
            "measurement_unit": getattr(record, 'measurement_unit', ''),
            "measurement_value": getattr(record, 'measurement_value', None)
        })
        
        return entry
```

#### ðŸ“ **Step 3.3: Create Logger Adapters Module**

**Create:** `scriptlets/foundation/logging/adapters.py`

```python
"""
Framework0 Foundation - Logger Adapters

Context-aware logger adapters for Framework0 integration:
- Framework0LoggerAdapter for automatic context inclusion
- Utility functions for performance and audit logging
- Thread-safe logger management for parallel execution
- Easy-to-use interfaces for other scriptlets
"""

from typing import Dict, Any, Optional, Union, Callable
import logging
import uuid
import threading
from datetime import datetime, timezone

from orchestrator.context import Context
from .core import LogEntry, create_timestamp
from .formatters import ContextAwareFormatter

class Framework0LoggerAdapter(logging.LoggerAdapter):
    """
    Logger adapter that automatically includes Framework0 context information.
    
    Provides seamless integration with Framework0 execution context:
    - Automatic recipe and step information extraction
    - Unique execution ID generation for tracking
    - Thread-safe context management
    - Easy-to-use interface for other scriptlets
    """
    
    def __init__(self, logger: logging.Logger, context: Optional[Context] = None) -> None:
        """
        Initialize the Framework0 logger adapter.
        
        Args:
            logger: The base logger instance to wrap
            context: Framework0 context for extracting contextual information
        """
        super().__init__(logger, {})
        self.context: Optional[Context] = context
        self._execution_id: str = str(uuid.uuid4())[:8]  # Short execution ID
        self._lock: threading.Lock = threading.Lock()    # Thread safety
    
    def process(self, msg: str, kwargs: Dict[str, Any]) -> tuple:
        """
        Process log message and add Framework0 context information.
        
        Args:
            msg: Log message to process
            kwargs: Additional logging arguments
            
        Returns:
            Tuple of (message, kwargs) with context information added
        """
        with self._lock:  # Ensure thread safety
            # Get or create extra data dictionary
            extra = kwargs.get('extra', {})
            
            # Add execution tracking information
            extra['execution_id'] = self._execution_id
            extra['context_id'] = id(self.context) if self.context else None
            
            # Extract Framework0 context information if available
            if self.context:
                try:
                    # Extract recipe and step information from context
                    extra['recipe_name'] = self.context.get('recipe.name')
                    extra['step_name'] = self.context.get('current_step.name')
                    
                    # Add any additional context data that might be useful
                    extra['recipe_version'] = self.context.get('recipe.version')
                    extra['step_index'] = self.context.get('current_step.index')
                except Exception:
                    # If context extraction fails, continue without it
                    pass
            
            # Update kwargs with enhanced extra information
            kwargs['extra'] = extra
            
        return msg, kwargs
    
    def get_execution_id(self) -> str:
        """
        Get the unique execution ID for this adapter instance.
        
        Returns:
            Unique execution ID string
        """
        return self._execution_id
    
    def update_context(self, new_context: Optional[Context]) -> None:
        """
        Update the Framework0 context for this adapter.
        
        Args:
            new_context: New Framework0 context to use
        """
        with self._lock:
            self.context = new_context

class LoggerManager:
    """
    Thread-safe manager for Framework0 logger instances.
    
    Provides centralized management of logger adapters:
    - Thread-safe logger creation and retrieval
    - Consistent configuration across all loggers
    - Memory-efficient logger reuse
    - Easy cleanup and management
    """
    
    def __init__(self) -> None:
        """
        Initialize the logger manager.
        """
        self._loggers: Dict[str, Framework0LoggerAdapter] = {}
        self._lock: threading.Lock = threading.Lock()
    
    def get_logger(self, name: str, context: Optional[Context] = None) -> Framework0LoggerAdapter:
        """
        Get or create a Framework0 logger adapter.
        
        Args:
            name: Name for the logger (will be prefixed with 'framework0.')
            context: Framework0 context for the logger
            
        Returns:
            Framework0LoggerAdapter instance
        """
        full_name = f"framework0.{name}" if not name.startswith("framework0.") else name
        
        with self._lock:
            if full_name not in self._loggers:
                # Create new logger adapter
                base_logger = logging.getLogger(full_name)
                adapter = Framework0LoggerAdapter(base_logger, context)
                self._loggers[full_name] = adapter
            else:
                # Update context if provided
                if context is not None:
                    self._loggers[full_name].update_context(context)
            
            return self._loggers[full_name]
    
    def update_all_contexts(self, context: Optional[Context]) -> None:
        """
        Update context for all managed loggers.
        
        Args:
            context: New context to apply to all loggers
        """
        with self._lock:
            for adapter in self._loggers.values():
                adapter.update_context(context)
    
    def get_logger_count(self) -> int:
        """
        Get the number of managed loggers.
        
        Returns:
            Number of logger adapters being managed
        """
        with self._lock:
            return len(self._loggers)
    
    def clear_loggers(self) -> None:
        """
        Clear all managed loggers (useful for cleanup).
        """
        with self._lock:
            self._loggers.clear()

def create_logger_utilities(context: Optional[Context] = None) -> Dict[str, Any]:
    """
    Create a complete set of logging utilities for Framework0.
    
    Args:
        context: Optional Framework0 context for initial setup
        
    Returns:
        Dictionary containing all logging utilities and functions
    """
    logger_manager = LoggerManager()
    
    def log_performance_metric(metric_name: str, value: Union[int, float], 
                             unit: str = "", **kwargs) -> None:
        """Log a performance metric in structured format."""
        perf_logger = logger_manager.get_logger("performance", context)
        metric_data = {
            "metric_name": metric_name,
            "value": value,
            "unit": unit,
            "timestamp": create_timestamp(),
            **kwargs
        }
        perf_logger.info(f"Performance: {metric_name} = {value} {unit}",
                        extra={"extra_data": metric_data})
    
    def log_audit_event(event_type: str, details: Dict[str, Any], **kwargs) -> None:
        """Log an audit event for compliance tracking."""
        audit_logger = logger_manager.get_logger("audit", context)
        audit_data = {
            "event_type": event_type,
            "details": details,
            "timestamp": create_timestamp(),
            **kwargs
        }
        audit_logger.info(f"Audit: {event_type}", extra={"extra_data": audit_data})
    
    def log_error_with_context(error: Exception, operation: str, **kwargs) -> None:
        """Log an error with full context information."""
        error_logger = logger_manager.get_logger("errors", context)
        error_data = {
            "error_type": type(error).__name__,
            "error_message": str(error),
            "operation": operation,
            "timestamp": create_timestamp(),
            **kwargs
        }
        error_logger.error(f"Error in {operation}: {error}", 
                          exc_info=True, extra={"extra_data": error_data})
    
    return {
        "logger_manager": logger_manager,
        "get_logger": lambda name, ctx=context: logger_manager.get_logger(name, ctx),
        "log_performance": log_performance_metric,
        "log_audit": log_audit_event,
        "log_error": log_error_with_context
    }
```

#### ðŸ“ **Step 3.4: Create Main Logging Scriptlet**

**Create:** `scriptlets/foundation/logging_framework.py`

```python
"""
Framework0 Foundation - Main Logging Framework Scriptlet

Orchestration and integration layer for the modular logging system:
- Coordinates all logging components (core, formatters, adapters)
- Manages logging infrastructure setup and configuration
- Provides Framework0 integration and context management
- Handles log rotation, directory creation, and cleanup
"""

from scriptlets.framework import BaseScriptlet, register_scriptlet
from orchestrator.context import Context
from typing import Dict, Any, List, Optional
from src.core.logger import get_logger
import os
import time
import logging
import logging.handlers
import pathlib
import sys

# Import our modular logging components
from .logging.core import (
    LogLevel, LogFormat, LogOutput, LoggingConfiguration,
    get_default_logging_config, merge_logging_configs
)
from .logging.formatters import (
    ContextAwareFormatter, AuditFormatter, PerformanceFormatter
)
from .logging.adapters import (
    Framework0LoggerAdapter, LoggerManager, create_logger_utilities
)

# Configure base logger for this module
logger = get_logger(__name__, debug=os.getenv("DEBUG") == "1")

@register_scriptlet
class LoggingFrameworkScriptlet(BaseScriptlet):
    """
    Main logging framework scriptlet for Framework0 infrastructure.
    
    Orchestrates the complete logging system setup:
    - Initializes modular logging components
    - Configures multiple output targets and formats
    - Sets up log rotation and directory management
    - Provides Framework0-aware logging utilities
    - Manages logging infrastructure lifecycle
    """
    
    def __init__(self) -> None:
        """Initialize the logging framework scriptlet."""
        super().__init__()
        self.name = "logging_framework"
        self.version = "2.0.0"  # Modular version
        self.description = "Modular production-ready logging infrastructure"
        
        # Internal state management
        self._loggers: Dict[str, logging.Logger] = {}
        self._handlers: List[logging.Handler] = []
        self._logger_manager: Optional[LoggerManager] = None
        self._configuration: Optional[LoggingConfiguration] = None
        
    def run(self, context: Context, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        Initialize and configure the modular logging framework.
        
        Args:
            context: Framework0 context for configuration and state management
            params: Configuration parameters for logging setup
            
        Returns:
            Dict containing logging framework setup results
        """
        try:
            start_time = time.time()
            logger.info(f"ðŸ—‚ï¸ Starting {self.name} v{self.version} - Modular Setup")
            
            # Extract and validate parameters
            logging_config = params["logging_config"]
            create_dirs = params.get("create_log_directories", True)
            setup_rotation = params.get("setup_log_rotation", True)
            
            print(f"ðŸ—‚ï¸ Framework0 Modular Logging Infrastructure")
            print(f"   ðŸ“‹ Version: {self.version}")
            print(f"   ðŸ§© Modular Architecture: ENABLED")
            
            # Initialize configuration
            base_config = get_default_logging_config()
            merged_config = merge_logging_configs(base_config, logging_config)
            self._configuration = LoggingConfiguration(merged_config)
            
            # Create directories if needed
            directories_created = []
            if create_dirs:
                directories_created = self._create_log_directories()
                print(f"   ðŸ“ Directories created: {len(directories_created)}")
            
            # Setup logging infrastructure
            loggers_configured = self._setup_logging_infrastructure(context)
            print(f"   ðŸ”§ Loggers configured: {len(loggers_configured)}")
            
            # Initialize utilities
            utilities = create_logger_utilities(context)
            self._logger_manager = utilities["logger_manager"]
            
            # Setup rotation if enabled
            rotation_count = 0
            if setup_rotation:
                rotation_count = self._setup_log_rotation()
                print(f"   ðŸ”„ Rotation handlers: {rotation_count}")
            
            # Store in context for other scriptlets
            context.set("logging.configuration", self._configuration, who=self.name)
            context.set("logging.utilities", utilities, who=self.name)
            context.set("logging.manager", self._logger_manager, who=self.name)
            context.set("logging.loggers", self._loggers, who=self.name)
            
            # Test the system
            test_results = self._test_logging_system(context)
            
            setup_time = time.time() - start_time
            
            print(f"   ðŸ“Š Setup completed in {setup_time:.2f}s")
            print(f"   âœ… Tests passed: {test_results['passed']}/{test_results['total']}")
            
            logger.info(f"âœ… Modular logging framework initialized successfully")
            
            return {
                "status": "success",
                "version": self.version,
                "setup_time_seconds": setup_time,
                "loggers_configured": len(loggers_configured),
                "handlers_created": len(self._handlers),
                "directories_created": directories_created,
                "rotation_handlers": rotation_count,
                "test_results": test_results,
                "execution_time": self.get_execution_time()
            }
            
        except Exception as e:
            logger.error(f"âŒ {self.name} execution failed: {e}")
            context.set(f"{self.name}.error", str(e), who=self.name)
            raise
    
    def _create_log_directories(self) -> List[str]:
        """Create necessary log directories."""
        directories = set()
        
        # Extract paths from configuration
        for section_name in ["framework", "audit", "performance"]:
            if self._configuration.is_section_enabled(section_name):
                config_getter = getattr(self._configuration, f"get_{section_name}_config")
                section_config = config_getter()
                file_path = section_config.get("file_path")
                if file_path:
                    directories.add(str(pathlib.Path(file_path).parent))
        
        # Create directories
        created = []
        for directory in directories:
            dir_path = pathlib.Path(directory)
            if not dir_path.exists():
                dir_path.mkdir(parents=True, exist_ok=True)
                created.append(str(dir_path))
        
        return created
    
    def _setup_logging_infrastructure(self, context: Context) -> List[str]:
        """Setup core logging infrastructure."""
        configured_loggers = []
        
        # Setup framework logging
        if self._configuration.is_section_enabled("framework"):
            framework_config = self._configuration.get_framework_config()
            self._setup_framework_logger(framework_config)
            configured_loggers.append("framework0")
        
        # Setup audit logging
        if self._configuration.is_section_enabled("audit"):
            audit_config = self._configuration.get_audit_config()
            self._setup_audit_logger(audit_config)
            configured_loggers.append("audit")
        
        # Setup performance logging
        if self._configuration.is_section_enabled("performance"):
            perf_config = self._configuration.get_performance_config()
            self._setup_performance_logger(perf_config)
            configured_loggers.append("performance")
        
        return configured_loggers
    
    def _setup_framework_logger(self, config: Dict[str, Any]) -> None:
        """Setup main framework logger."""
        framework_logger = logging.getLogger("framework0")
        framework_logger.handlers.clear()
        
        # Set level
        log_level = getattr(LogLevel, config.get("level", "INFO").upper())
        framework_logger.setLevel(log_level.value)
        
        # Create formatters
        json_formatter = ContextAwareFormatter(LogFormat.STRUCTURED_JSON)
        text_formatter = ContextAwareFormatter(LogFormat.SIMPLE_TEXT)
        
        # Console handler
        outputs = config.get("outputs", ["console"])
        if "console" in outputs:
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setFormatter(text_formatter)
            framework_logger.addHandler(console_handler)
            self._handlers.append(console_handler)
        
        # File handler
        if "file" in outputs and config.get("file_path"):
            file_handler = logging.FileHandler(config["file_path"])
            file_handler.setFormatter(json_formatter)
            framework_logger.addHandler(file_handler)
            self._handlers.append(file_handler)
        
        self._loggers["framework0"] = framework_logger
    
    def _setup_audit_logger(self, config: Dict[str, Any]) -> None:
        """Setup audit logger."""
        audit_logger = logging.getLogger("framework0.audit")
        audit_logger.handlers.clear()
        audit_logger.setLevel(logging.INFO)
        
        file_handler = logging.FileHandler(config["file_path"])
        file_handler.setFormatter(AuditFormatter())
        audit_logger.addHandler(file_handler)
        self._handlers.append(file_handler)
        
        self._loggers["audit"] = audit_logger
    
    def _setup_performance_logger(self, config: Dict[str, Any]) -> None:
        """Setup performance logger."""
        perf_logger = logging.getLogger("framework0.performance")
        perf_logger.handlers.clear()
        perf_logger.setLevel(logging.INFO)
        
        file_handler = logging.FileHandler(config["file_path"])
        file_handler.setFormatter(PerformanceFormatter())
        perf_logger.addHandler(file_handler)
        self._handlers.append(file_handler)
        
        self._loggers["performance"] = perf_logger
    
    def _setup_log_rotation(self) -> int:
        """Setup log rotation for file handlers."""
        framework_config = self._configuration.get_framework_config()
        rotation_config = framework_config.get("rotation", {})
        
        if not rotation_config.get("enabled", False):
            return 0
        
        max_size_mb = rotation_config.get("max_size_mb", 100)
        max_files = rotation_config.get("max_files", 10)
        max_bytes = max_size_mb * 1024 * 1024
        
        rotation_count = 0
        
        # Replace file handlers with rotating versions
        for handler in self._handlers[:]:
            if isinstance(handler, logging.FileHandler):
                if not isinstance(handler, logging.handlers.RotatingFileHandler):
                    # Create rotating version
                    rotating_handler = logging.handlers.RotatingFileHandler(
                        handler.baseFilename, maxBytes=max_bytes, backupCount=max_files
                    )
                    rotating_handler.setLevel(handler.level)
                    rotating_handler.setFormatter(handler.formatter)
                    
                    # Replace in loggers
                    for logger_instance in self._loggers.values():
                        if handler in logger_instance.handlers:
                            logger_instance.removeHandler(handler)
                            logger_instance.addHandler(rotating_handler)
                    
                    # Update handler list
                    self._handlers.remove(handler)
                    self._handlers.append(rotating_handler)
                    rotation_count += 1
        
        return rotation_count
    
    def _test_logging_system(self, context: Context) -> Dict[str, Any]:
        """Test the complete logging system."""
        test_results = {"passed": 0, "total": 0, "details": []}
        
        # Test framework logging
        test_results["total"] += 1
        try:
            if "framework0" in self._loggers:
                self._loggers["framework0"].info("Modular logging test - framework")
                test_results["passed"] += 1
                test_results["details"].append({"test": "framework", "status": "passed"})
        except Exception as e:
            test_results["details"].append({"test": "framework", "status": "failed"})
        
        # Test logger manager
        test_results["total"] += 1
        try:
            if self._logger_manager:
                test_logger = self._logger_manager.get_logger("test", context)
                test_logger.info("Modular logging test - manager")
                test_results["passed"] += 1
                test_results["details"].append({"test": "manager", "status": "passed"})
        except Exception as e:
            test_results["details"].append({"test": "manager", "status": "failed"})
        
        # Test utilities
        test_results["total"] += 1
        try:
            utilities = create_logger_utilities(context)
            test_adapter = utilities["get_logger"]("utilities_test")
            test_adapter.info("Modular logging test - utilities")
            test_results["passed"] += 1
            test_results["details"].append({"test": "utilities", "status": "passed"})
        except Exception as e:
            test_results["details"].append({"test": "utilities", "status": "failed"})
        
        return test_results
```

#### ðŸ“ **Step 3.5: Create Module Initialization**

**Create:** `scriptlets/foundation/logging/__init__.py`

```python
"""
Framework0 Foundation - Logging Module

Modular production-ready logging infrastructure for Framework0.
Provides clean exports and initialization for easy integration.
"""

# Core exports
from .core import (
    LogLevel, LogFormat, LogOutput, LogEntry, LoggingConfiguration,
    create_timestamp, validate_log_level, get_default_logging_config
)

# Formatter exports  
from .formatters import (
    ContextAwareFormatter, AuditFormatter, PerformanceFormatter
)

# Adapter exports
from .adapters import (
    Framework0LoggerAdapter, LoggerManager, create_logger_utilities
)

# Module information
__version__ = "2.0.0"
__description__ = "Modular logging infrastructure for Framework0"

# Convenience function for quick setup
def get_framework_logger(name: str = "framework0", context=None):
    """Get a Framework0 logger quickly."""
    utilities = create_logger_utilities(context)
    return utilities["get_logger"](name)

# All exports
__all__ = [
    "LogLevel", "LogFormat", "LogOutput", "LogEntry", "LoggingConfiguration",
    "ContextAwareFormatter", "AuditFormatter", "PerformanceFormatter", 
    "Framework0LoggerAdapter", "LoggerManager", "create_logger_utilities",
    "create_timestamp", "validate_log_level", "get_default_logging_config",
    "get_framework_logger", "__version__"
]
```

## ðŸŽ¯ **Modular Logging Framework Complete!**

### **Architecture Summary:**

```
scriptlets/foundation/
â”œâ”€â”€ logging/
â”‚   â”œâ”€â”€ __init__.py        # Clean exports (60 lines)
â”‚   â”œâ”€â”€ core.py           # Enums, data classes, utilities (300 lines)
â”‚   â”œâ”€â”€ formatters.py     # Formatting logic (400 lines)
â”‚   â””â”€â”€ adapters.py       # Context adapters and utilities (350 lines)
â””â”€â”€ logging_framework.py  # Main orchestration scriptlet (450 lines)
```

**âœ… Team Guidelines Compliance:**
- **Modularity:** Clean separation with focused responsibilities
- **Line Limits:** All files under 500 lines
- **Type Safety:** Full type hints throughout
- **Documentation:** Comprehensive docstrings
- **Testing:** Built-in validation functionality

### Step 4: Create Foundation Configuration Initializer

**ðŸ“ Create:** `scriptlets/foundation/config_initializer.py`

```python
"""
Framework0 Foundation - Configuration Management System

Enterprise configuration management designed for:
- Environment-aware configuration loading and validation
- Runtime parameter injection and overrides
- Configuration schema validation and type checking
- Secure credential management and encryption
- Configuration change tracking and auditing
"""

from scriptlets.framework import BaseScriptlet, register_scriptlet
from orchestrator.context import Context
from typing import Dict, Any, List, Optional, Union
from src.core.logger import get_logger
import os
import json
import jsonschema
import pathlib
from datetime import datetime
import copy

logger = get_logger(__name__, debug=os.getenv("DEBUG") == "1")

@register_scriptlet
class FoundationConfigInitializerScriptlet(BaseScriptlet):
    """
    Foundation configuration management and initialization.
    
    Features:
    - Environment-aware configuration loading
    - Parameter injection and runtime overrides
    - Configuration validation against schemas
    - Secure credential handling
    - Configuration change auditing
    """
    
    def __init__(self) -> None:
        """Initialize the configuration initializer."""
        super().__init__()
        self.name = "foundation_config_initializer"
        self.version = "1.0.0"
        self.description = "Enterprise configuration management for Framework0 foundation"
        
    def run(self, context: Context, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        Load and initialize foundation configuration with validation.
        
        Args:
            context: Framework0 context for configuration storage
            params: Configuration parameters and overrides
            
        Returns:
            Dict containing configuration loading results and validation status
        """
        try:
            start_time = time.time()
            logger.info(f"âš™ï¸ Starting {self.name} - Configuration Initialization")
            
            # Extract parameters
            config_path = params["config_path"]
            environment_override = params.get("environment_override", True)
            parameter_injection = params.get("parameter_injection", {})
            
            print(f"âš™ï¸ Foundation Configuration Initialization")
            print(f"   ðŸ“ Config Source: {config_path}")
            print(f"   ðŸŒ Environment Override: {'ENABLED' if environment_override else 'DISABLED'}")
            print(f"   ðŸ’‰ Parameter Injection: {len(parameter_injection)} parameters")
            
            # Load base configuration
            base_config = self._load_base_configuration(config_path)
            print(f"     âœ… Base configuration loaded: {len(base_config)} sections")
            
            # Apply environment overrides if enabled
            if environment_override:
                env_overrides = self._apply_environment_overrides(base_config)
                print(f"     ðŸŒ Environment overrides applied: {len(env_overrides)}")
            
            # Inject runtime parameters
            if parameter_injection:
                injected_params = self._inject_parameters(base_config, parameter_injection)
                print(f"     ðŸ’‰ Parameters injected: {len(injected_params)}")
            
            # Validate configuration
            validation_results = self._validate_configuration(base_config)
            print(f"     ðŸ” Configuration validation: {'âœ… PASSED' if validation_results['valid'] else 'âŒ FAILED'}")
            
            # Store configuration in context with proper structure
            self._store_configuration_in_context(context, base_config)
            
            # Create configuration utilities
            config_utilities = self._create_configuration_utilities(context, base_config)
            context.set("foundation.config_utilities", config_utilities, who=self.name)
            
            setup_time = time.time() - start_time
            
            print(f"   â±ï¸ Configuration setup completed in {setup_time:.2f} seconds")
            
            logger.info(f"âœ… Foundation configuration initialized successfully")
            
            return {
                "status": "success",
                "config_sections": len(base_config),
                "validation_passed": validation_results['valid'],
                "environment_overrides": len(env_overrides) if environment_override else 0,
                "parameter_injections": len(injected_params) if parameter_injection else 0,
                "setup_time_seconds": setup_time,
                "execution_time": self.get_execution_time()
            }
            
        except Exception as e:
            logger.error(f"âŒ {self.name} execution failed: {e}")
            context.set(f"{self.name}.error", str(e), who=self.name)
            raise
    
    def _load_base_configuration(self, config_path: str) -> Dict[str, Any]:
        """Load base configuration from file."""
        
        config_file = pathlib.Path(config_path)
        if not config_file.exists():
            raise FileNotFoundError(f"Configuration file not found: {config_path}")
        
        with open(config_file, 'r') as f:
            if config_path.endswith('.json'):
                return json.load(f)
            elif config_path.endswith('.yaml') or config_path.endswith('.yml'):
                import yaml
                return yaml.safe_load(f)
            else:
                raise ValueError(f"Unsupported configuration file format: {config_path}")
    
    def _apply_environment_overrides(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Apply environment variable overrides to configuration."""
        
        env_overrides = {}
        
        # Define environment variable mapping patterns
        env_mappings = {
            "FRAMEWORK0_LOG_LEVEL": ["logging", "framework", "level"],
            "FRAMEWORK0_DEBUG": ["foundation", "debug_level"],
            "FRAMEWORK0_ENV": ["foundation", "environment"],
            "FRAMEWORK0_MONITORING": ["monitoring", "health_checks", "enabled"]
        }
        
        for env_var, config_path in env_mappings.items():
            env_value = os.getenv(env_var)
            if env_value is not None:
                # Navigate to the configuration section
                current_section = config
                for path_component in config_path[:-1]:
                    current_section = current_section.setdefault(path_component, {})
                
                # Set the value with type conversion
                final_key = config_path[-1]
                converted_value = self._convert_env_value(env_value)
                current_section[final_key] = converted_value
                env_overrides[env_var] = converted_value
        
        return env_overrides
    
    def _convert_env_value(self, value: str) -> Union[str, int, float, bool]:
        """Convert environment variable string to appropriate type."""
        
        # Boolean conversion
        if value.lower() in ('true', 'yes', '1', 'on'):
            return True
        elif value.lower() in ('false', 'no', '0', 'off'):
            return False
        
        # Numeric conversion
        try:
            if '.' in value:
                return float(value)
            else:
                return int(value)
        except ValueError:
            pass
        
        # Return as string
        return value
    
    def _inject_parameters(self, config: Dict[str, Any], parameter_injection: Dict[str, Any]) -> Dict[str, Any]:
        """Inject runtime parameters into configuration."""
        
        injected_params = {}
        
        for param_name, param_value in parameter_injection.items():
            # Map parameter names to configuration paths
            param_mappings = {
                "logging_level": ["logging", "framework", "level"],
                "monitoring_enabled": ["monitoring", "health_checks", "enabled"],
                "performance_tracking": ["performance", "benchmarking", "enabled"],
                "error_recovery_enabled": ["error_handling", "automatic_recovery", "enabled"]
            }
            
            if param_name in param_mappings:
                config_path = param_mappings[param_name]
                
                # Navigate to configuration section
                current_section = config
                for path_component in config_path[:-1]:
                    current_section = current_section.setdefault(path_component, {})
                
                # Set the parameter value
                final_key = config_path[-1]
                current_section[final_key] = param_value
                injected_params[param_name] = param_value
        
        return injected_params
    
    def _validate_configuration(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Validate configuration against expected schema."""
        
        validation_results = {
            "valid": True,
            "errors": [],
            "warnings": []
        }
        
        # Define expected configuration structure
        required_sections = ["foundation", "logging", "monitoring", "performance", "error_handling"]
        
        # Check required sections
        for section in required_sections:
            if section not in config:
                validation_results["errors"].append(f"Missing required section: {section}")
                validation_results["valid"] = False
        
        # Validate logging configuration
        if "logging" in config:
            logging_config = config["logging"]
            if "framework" not in logging_config:
                validation_results["errors"].append("Missing logging.framework configuration")
                validation_results["valid"] = False
        
        # Validate monitoring configuration
        if "monitoring" in config:
            monitoring_config = config["monitoring"]
            if "health_checks" not in monitoring_config:
                validation_results["warnings"].append("No health_checks configuration found")
        
        return validation_results
    
    def _store_configuration_in_context(self, context: Context, config: Dict[str, Any]):
        """Store configuration in context with proper structure."""
        
        # Store complete configuration
        context.set("foundation.config", config, who=self.name)
        
        # Store individual sections for easy access
        for section_name, section_config in config.items():
            context.set(f"foundation.config.{section_name}", section_config, who=self.name)
    
    def _create_configuration_utilities(self, context: Context, config: Dict[str, Any]) -> Dict[str, Any]:
        """Create configuration utility functions."""
        
        def get_config_value(path: str, default: Any = None) -> Any:
            """Get configuration value by dot-separated path."""
            try:
                keys = path.split('.')
                current = config
                for key in keys:
                    current = current[key]
                return current
            except (KeyError, TypeError):
                return default
        
        def update_config_value(path: str, value: Any) -> bool:
            """Update configuration value by dot-separated path."""
            try:
                keys = path.split('.')
                current = config
                for key in keys[:-1]:
                    current = current.setdefault(key, {})
                current[keys[-1]] = value
                
                # Update context as well
                context.set("foundation.config", config, who="config_update")
                return True
            except Exception:
                return False
        
        return {
            "get_config_value": get_config_value,
            "update_config_value": update_config_value,
            "config_sections": list(config.keys())
        }
```

## ðŸ¤” **Implementation Feedback Checkpoint**

I've created the **comprehensive LoggingFrameworkScriptlet** with production-ready features:

### **Key Features Implemented:**

1. **Structured JSON Logging** - Context-aware log entries with Framework0 metadata
2. **Multiple Output Targets** - Console, file, and rotating file handlers
3. **Thread-Safe Operations** - Safe for parallel recipe execution
4. **Performance Optimized** - Efficient logging with minimal overhead
5. **Configuration Driven** - Flexible setup through external configuration
6. **Framework0 Integration** - Context-aware logging with recipe/step information

### **Architecture Highlights:**

- **`ContextAwareFormatter`** - Automatically includes Framework0 context in all log entries
- **`Framework0LoggerAdapter`** - Provides easy-to-use logging for other scriptlets
- **Production Features** - Log rotation, audit logging, performance logging
- **Testing Integration** - Built-in functionality tests to verify proper setup

**Questions for your feedback:**

1. **Is this level of comprehensive logging what you envisioned for the foundation?**
2. **Should I proceed with the next foundation scriptlet (HealthMonitoringScriptlet) or refine this one?**
3. **Do you want to test the logging framework before moving to the next component?**
4. **Are there specific logging integrations you need (external logging systems, monitoring tools)?**

**Next steps options:**
- **Test the logging framework** by creating a simple test recipe
- **Implement HealthMonitoringScriptlet** to build on the logging foundation  
- **Add more logging features** (remote logging, log aggregation, etc.)

**What would you like to focus on next?**

## ðŸ¤” **Feedback Checkpoint - Foundation Architecture**

**I've designed the infrastructure bootstrap to initialize 5 core systems:**

1. **Configuration Management** - Centralized, environment-aware settings
2. **Logging Framework** - Structured logging with multiple outputs  
3. **Health Monitoring** - Real-time system and application health
4. **Performance Metrics** - Execution tracking and benchmarking
5. **Error Handling** - Centralized error management with recovery

**Questions for your feedback:**

### **Architecture Review:**
1. **Does this foundation structure make sense as a reusable dependency for future recipes?**
2. **Are there other core infrastructure components I should include at this level?**
3. **Is the parameter-driven approach (logging_level, monitoring_enabled, etc.) flexible enough?**

### **Implementation Priority:**
1. **Which of the 5 foundation scriptlets should I implement first and in detail?**
2. **Should I focus on the logging framework first, or would you prefer health monitoring?**
3. **Do you want to see the complete bootstrap recipe working before we add more foundation recipes?**

### **Configuration Approach:**
1. **Is the JSON-based configuration structure appropriate, or do you prefer YAML?**
2. **Should configuration support environment variables and runtime overrides?**
3. **Do you need specific integrations (e.g., external logging systems, monitoring tools)?**

### **Next Steps Options:**

**Option A:** Complete the foundation scriptlet implementations (LoggingFrameworkScriptlet, HealthMonitoringScriptlet, etc.)

**Option B:** Add more foundation recipes (system diagnostics, network connectivity, security validation)

**Option C:** Create the testing framework to validate the foundation infrastructure

**Which direction should I take next? And do you have any feedback on the foundation architecture design so far?**
